{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UqVw4P9xDONr"
   },
   "source": [
    "<figure>\n",
    "  <img src=\"https://github.com/v-iashin/video_features/raw/master/docs/_assets/r21d.png\" width=\"300\" />\n",
    "</figure>\n",
    "\n",
    "The `video_features` library allows you to extract features from\n",
    "raw videos in parallel with multiple GPUs.\n",
    "It supports several extractors that capture visual appearance,\n",
    "optical flow, and audio features. See more details in the\n",
    "[GitHub repository](https://github.com/v-iashin/video_features).\n",
    "\n",
    "See more feature extraction examples in colaboratory notebooks:\n",
    "* [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1Zd7r8uKGLGSxlil4PPnXk_4I3KOsjPpO?usp=sharing) – CLIP\n",
    "* [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1HUlYcOJf_dArOcAaR9jaQHuM5CAZiNZc?usp=sharing) – S3D\n",
    "* [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1LKoytZmNxtC-EuCp7pHDM6sFvK1XdwlW?usp=sharing) – I3D\n",
    "* [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1csJgkVQ3E2qOyVlcOM-ACHGgPBBKwE2Y?usp=sharing) – R(2+1)D\n",
    "* [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/18I95Rn1B3a2ISfD9b-o4o93m3XuHbcIY?usp=sharing) – RAFT\n",
    "* [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/17VLdf4abQT2eoMjc6ziJ9UaRaOklTlP0?usp=sharing) – ResNet\n",
    "* [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1r_8OnmwXKwmH0n4RxBfuICVBgpbJt_Fs?usp=sharing) – VGGish\n",
    "* [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/16QEwNMqiwqlmBhJCJmNeeEP8gitom0I-?usp=sharing) – [timm](https://huggingface.co/timm) models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T23:46:49.220350Z",
     "start_time": "2024-06-17T23:46:47.198688Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "Gn1MrAwGGkyY",
    "outputId": "304e029a-aeb5-4740-af14-cfb6f09df5d5"
   },
   "source": [
    "import os\n",
    "! git clone https://github.com/v-iashin/video_features.git\n",
    "! pip install omegaconf==2.0.6 av==10.0"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T23:47:04.636777Z",
     "start_time": "2024-06-17T23:47:04.631164Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uq-_J-msB8Px",
    "outputId": "bebcc372-f87e-4971-dc34-a3ca136f0df5"
   },
   "source": [
    "%cd video_features\n",
    "%pwd"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T23:47:09.635760Z",
     "start_time": "2024-06-17T23:47:09.632460Z"
    }
   },
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "os.chdir('F:\\Machine_learning\\P_3\\\\video_features')\n",
    "print(os.getcwd())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T23:47:34.640076Z",
     "start_time": "2024-06-17T23:47:27.219217Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "6Czo1UciGomZ",
    "outputId": "ea0bb0bb-966a-4232-abff-61ed34c28686"
   },
   "source": [
    "from video_features.models.r21d.extract_r21d import ExtractR21D\n",
    "from video_features.utils.utils import build_cfg_path\n",
    "from omegaconf import OmegaConf\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "torch.cuda.get_device_name(0)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add all the videos to process the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T16:02:37.493973Z",
     "start_time": "2024-06-13T16:02:37.067990Z"
    }
   },
   "source": [
    "import  os\n",
    "import numpy as np\n",
    "\n",
    "import shutil\n",
    "print(os.getcwd())\n",
    "os.chdir('F:\\\\Machine_learning\\\\P_3') #use your local machine path \n",
    "\n",
    "\n",
    "source_dir = 'train_subset'\n",
    "target_dir1 = 'train_subset_1' #Fabricio\n",
    "target_dir2 = 'train_subset_2'  #Furro Egus\n",
    "\n",
    "\n",
    "\n",
    "path = os.getcwd()\n",
    "files = os.listdir(path+'\\\\'+source_dir)\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create target directories if they don't exist\n",
    "os.makedirs(target_dir1, exist_ok=True)\n",
    "os.makedirs(target_dir2, exist_ok=True)\n",
    "\n",
    "print(\"Total  train list \",len(files))\n",
    "\n",
    "# Split the files into two equal parts\n",
    "midpoint = len(files) // 2\n",
    "files_part1 = files[:midpoint]\n",
    "files_part2 = files[midpoint:]\n",
    "\n",
    "# Move the files to the respective target directories\n",
    "for file in files_part1:\n",
    "    shutil.move(os.path.join(source_dir, file), os.path.join(target_dir1, file))\n",
    "\n",
    "for file in files_part2:\n",
    "    shutil.move(os.path.join(source_dir, file), os.path.join(target_dir2, file))\n",
    "\n",
    "print(f'Files have been divided and moved to {target_dir1} and {target_dir2}')\n",
    "\n",
    "\n",
    "\n",
    "feature_path = \"F:\\\\Machine_learning\\\\P_3\\\\train_subset_features\" #use your local machine path \n",
    "train_path = \"F:/Machine_learning/P_3/\" + target_dir1 #use your local machine path  also  #Change here into part2 for Egus :3\n",
    "\n",
    "if len(files_part1) ==0 : #Change here into part2 for Furro Egus :3 \n",
    "    files_part1 = os.listdir(train_path)\n",
    "\n",
    "\n",
    "if not os.path.exists(feature_path):\n",
    "    os.makedirs(feature_path)\n",
    "\n",
    "train_list = [os.path.join(train_path, f) for f in files_part1]\n",
    "print(\"Your new work load is\" ,train_path +'----->'+ str(len(train_list)))\n",
    "if os.access(feature_path, os.W_OK):\n",
    "    print(f\"Tienes permisos de escritura en el directorio: {feature_path}\")\n",
    "else:\n",
    "    print(f\"No tienes permisos de escritura en el directorio: {feature_path}\")    \n",
    "    "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T17:59:00.377698Z",
     "start_time": "2024-06-01T17:59:00.373953Z"
    }
   },
   "source": [
    "#restore the old path \n",
    "os.chdir('F:\\\\Machine_learning\\\\P_3\\\\video_features') #use your local machine path \n",
    "print(os.getcwd())\n",
    "print(feature_path) #use your local machine path "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T20:28:32.725031Z",
     "start_time": "2024-06-01T17:59:03.070292Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iMwy01A8w9nP",
    "outputId": "f0d4635a-6083-4a62-c7b5-80157fc8e985"
   },
   "source": [
    "# Cargar y ajustar la configuración\n",
    "feature_type = 'r21d'\n",
    "args = OmegaConf.load(build_cfg_path(feature_type))\n",
    "args.video_paths = train_list\n",
    "args.model_name = 'r2plus1d_18_16_kinetics'\n",
    "args.device = device\n",
    "\n",
    "# Cargar el modelo\n",
    "extractor = ExtractR21D(args)\n",
    "\n",
    "# Diccionario para almacenar las características\n",
    "all_features = {}\n",
    "\n",
    "# Contador de videos procesados\n",
    "processed_count = 0\n",
    "\n",
    "# Extraer características\n",
    "for video_path in args.video_paths:\n",
    "    processed_count += 1\n",
    "    video_name = os.path.basename(video_path)\n",
    "    \n",
    "    # Imprimir el video que se está procesando\n",
    "    #print(f'Extrayendo características para {video_name}')\n",
    "    \n",
    "    # Extraer características\n",
    "    try:\n",
    "        feature_dict = extractor.extract(video_path)\n",
    "        \n",
    "        # Verificar si se generan características\n",
    "        if not feature_dict:\n",
    "            print(f\"No se generaron características para {video_name}\")\n",
    "        else:\n",
    "            for k, v in feature_dict.items():\n",
    "                #print(f'This is key: {k}')\n",
    "                #print(f'This is value shape: {v.shape}')\n",
    "\n",
    "                # Guardar las características en el diccionario\n",
    "                video_key = os.path.basename(video_name).replace('.mp4', '')\n",
    "                if video_key not in all_features:\n",
    "                    all_features[video_key] = {}\n",
    "                    all_features[video_key][k] = v\n",
    "\n",
    "        # Mostrar el número de videos procesados\n",
    "        print(f'Videos procesados: {processed_count}')\n",
    "    \n",
    "    except RuntimeError as e:\n",
    "        print(f\"Error procesando {video_name}: {e}\")\n",
    "\n",
    "# Guardar todas las características a la memoria secundaria al final\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T20:29:40.018698Z",
     "start_time": "2024-06-01T20:29:33.865971Z"
    }
   },
   "source": [
    "for video_key, features in all_features.items():\n",
    "    for k, v in features.items():\n",
    "        output_file = os.path.join(feature_path, f'{video_key}.npy')\n",
    "        with open(output_file, 'wb') as f:\n",
    "            np.save(f, v)\n",
    "        print(f'Guardado: {output_file}')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process test_features from videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T00:46:37.164798Z",
     "start_time": "2024-06-18T00:06:12.236992Z"
    }
   },
   "source": [
    "test_path = \"F:/Machine_learning/P_3/test_subset\"  #use your local machine path  also  \n",
    "test_feature_path = \"F:/Machine_learning/P_3/test_subset_features\"\n",
    "test_files = os.listdir(test_path)\n",
    "test_list = [os.path.join(test_path, f) for f in test_files]\n",
    "feature_type = 'r21d'\n",
    "args = OmegaConf.load(build_cfg_path(feature_type))\n",
    "args.video_paths = test_list\n",
    "args.model_name = 'r2plus1d_18_16_kinetics'\n",
    "args.device = device\n",
    "\n",
    "# Cargar el modelo\n",
    "extractor = ExtractR21D(args)\n",
    "\n",
    "# Diccionario para almacenar las características\n",
    "all_features = {}\n",
    "\n",
    "# Contador de videos procesados\n",
    "processed_count = 0\n",
    "\n",
    "# Extraer características\n",
    "for video_path in args.video_paths:\n",
    "    processed_count += 1\n",
    "    video_name = os.path.basename(video_path)\n",
    "    \n",
    "    # Imprimir el video que se está procesando\n",
    "    #print(f'Extrayendo características para {video_name}')\n",
    "    \n",
    "    # Extraer características\n",
    "    try:\n",
    "        feature_dict = extractor.extract(video_path)\n",
    "        \n",
    "        # Verificar si se generan características\n",
    "        if not feature_dict:\n",
    "            print(f\"No se generaron características para {video_name}\")\n",
    "        else:\n",
    "            for k, v in feature_dict.items():\n",
    "                #print(f'This is key: {k}')\n",
    "                #print(f'This is value shape: {v.shape}')\n",
    "\n",
    "                # Guardar las características en el diccionario\n",
    "                video_key = os.path.basename(video_name).replace('.mp4', '')\n",
    "                if video_key not in all_features:\n",
    "                    all_features[video_key] = {}\n",
    "                    all_features[video_key][k] = v\n",
    "\n",
    "        # Mostrar el número de videos procesados\n",
    "        print(f'Videos procesados: {processed_count}')\n",
    "    \n",
    "    except RuntimeError as e:\n",
    "        print(f\"Error procesando {video_name}: {e}\")\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save data for testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T01:00:13.833392Z",
     "start_time": "2024-06-18T01:00:09.360414Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "for video_key, features in all_features.items():\n",
    "    for k, v in features.items():\n",
    "        output_file = os.path.join(test_feature_path, f'{video_key}.npy')\n",
    "        with open(output_file, 'wb') as f:\n",
    "            np.save(f, v)\n",
    "        print(f'Guardado: {output_file}')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar data guardada de los video features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T07:27:33.405443Z",
     "start_time": "2024-06-17T07:27:31.754879Z"
    }
   },
   "source": [
    "\n",
    "# Directorio donde están almacenados los archivos .npy\n",
    "feature_dir = 'F:\\\\Machine_learning\\\\P_3\\\\train_subset_features'\n",
    "import os\n",
    "import numpy as np\n",
    "# Listar todos los archivos .npy en el directorio\n",
    "feature_files = [f for f in os.listdir(feature_dir) if f.endswith('.npy')]\n",
    "\n",
    "# Cargar y procesar cada archivo .npy\n",
    "all_data = []\n",
    "all_names = []\n",
    "for file_name in feature_files:\n",
    "    file_path = os.path.join(feature_dir, file_name)\n",
    "    data = np.load(file_path)\n",
    "    if data.shape == (0,):\n",
    "        print(f'Skipping {file_name} because it is empty.')\n",
    "    elif data.shape[1] == 512:\n",
    "        print(f'Loaded {file_name} with shape: {data.shape}')\n",
    "        all_data.append(data)\n",
    "        all_names.append(file_name[0:11])\n",
    "    else:\n",
    "        print(f'Skipping {file_name} due to incorrect shape: {data.shape}')\n",
    "\n",
    "print(f'Loaded {len(all_data)} files.')\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T04:42:21.992113Z",
     "start_time": "2024-06-17T04:42:21.971567Z"
    }
   },
   "source": [
    "%pwd\n",
    "%cd ..\n",
    "%pwd"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T07:30:19.959357Z",
     "start_time": "2024-06-17T07:30:05.280784Z"
    }
   },
   "source": [
    "from Data_processing_support.feature_summary_techniques import apply_pca_fixed_components , apply_pca\n",
    "new_matrix = []\n",
    "for matrix in all_data:\n",
    "    m , n_comp =apply_pca(matrix , variance_threshold=0.95 )\n",
    "    print(n_comp)\n",
    "    new_matrix.append(m)\n",
    "print(all_data[0].shape)\n",
    "\n",
    " "
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROCESANDO DATA PARA CLUSTERS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T04:42:34.152506Z",
     "start_time": "2024-06-17T04:42:29.952455Z"
    }
   },
   "source": [
    "# SACANDO MEDIA PARA CADA DATO DE all_data\n",
    "from Data_processing_support.feature_summary_techniques import summary_by_mean\n",
    "print(\"size of data : \" , all_data[10223].shape)\n",
    "print(\"size of labels : \" , len(all_names))\n",
    "np_mean=summary_by_mean(all_data)\n",
    "print(\"New data frame values and categories :\" , np_mean.shape)\n",
    "print(all_names[0:10])\n",
    "#print(\"Nuevo data frame sizes \" , df_mean.shape)\n",
    "df = pd.DataFrame(np_mean)\n",
    "df.to_csv('train_mean.csv')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usando Kmeans para procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T04:16:23.431755Z",
     "start_time": "2024-06-17T04:16:21.325071Z"
    }
   },
   "source": [
    "# Aplicar KMeans\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans , DBSCAN\n",
    "from Data_processing_support.feature_summary_techniques import add_true_categories_to_data_frame  , get_all_metrics\n",
    "kmeans  = KMeans(n_clusters=20, random_state=42)\n",
    "labels = kmeans.fit_predict(np_mean)\n",
    "df_mean = pd.DataFrame(np_mean)\n",
    "\n",
    "df_mean['video'] = all_names\n",
    "df_mean['cluster'] = labels\n",
    "\n",
    "df_mean = add_true_categories_to_data_frame(df_mean)\n",
    "\n",
    "print(df_mean[['video', 'category' ,'cluster' ]].head())\n",
    "\n",
    "true_labels = df_mean['category']\n",
    "predicted_labels = df_mean['cluster']\n",
    "\n",
    "get_all_metrics(predicted_labels, true_labels , np_mean)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agglomerating method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T17:10:43.699776Z",
     "start_time": "2024-06-17T17:10:43.694199Z"
    }
   },
   "source": [
    "%pwd"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T17:10:58.888313Z",
     "start_time": "2024-06-17T17:10:44.402096Z"
    }
   },
   "source": [
    "from scipy.cluster.hierarchy import linkage  , dendrogram \n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "clustering  = AgglomerativeClustering(n_clusters=20)\n",
    "labels = clustering.fit_predict(np_mean)\n",
    "df_mean = pd.DataFrame(np_mean)\n",
    "\n",
    "df_mean['video'] = all_names\n",
    "df_mean['cluster'] = labels\n",
    "\n",
    "df_mean = add_true_categories_to_data_frame(df_mean)\n",
    "\n",
    "print(df_mean[['video', 'category' ,'cluster' ]].head())\n",
    "\n",
    "true_labels = df_mean['category']\n",
    "predicted_labels = df_mean['cluster']\n",
    "\n",
    "get_all_metrics(labels, true_labels , np_mean)\n",
    "\n",
    "\n",
    "\n",
    "# Sample data\n",
    "np.random.seed(0)\n",
    "X = np.random.rand(10, 2)  # 10 points in 2 dimensions\n",
    "\n",
    "# Perform hierarchical clustering using different linkage methods\n",
    "Z_single = linkage(X, 'single')\n",
    "\n",
    "\n",
    "print(Z_single)\n",
    "plt.figure(figsize=(10, 7))\n",
    "dendrogram(Z_single)\n",
    "plt.title('Dendrograma de Agrupamiento Jerárquico')\n",
    "plt.xlabel('Índice de muestra')\n",
    "plt.ylabel('Distancia')\n",
    "plt.show()\n",
    "    "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T04:13:22.214911Z",
     "start_time": "2024-06-17T04:13:20.317160Z"
    }
   },
   "source": [
    "from Cluster_Models.Agglomerate_method import AgglomerativeMethod  , cluster\n",
    "import heapq\n",
    "list = [(3 ,'A'  ,'C'),(5 , 'B' , 'D'),(1,'F' , 'MN'),(6,'E' , 'HI'),(10,'D' , 'L')]\n",
    "\n",
    "heapq.heapify(list)\n",
    "heapq.heappush(list, (-1,'MOMOKA :3' , 'coso'))\n",
    "print(list)\n",
    "\n",
    "dict = {}\n",
    "\n",
    "for i, element in zip(range(len(list)), list):\n",
    "    key = element[1]+element[2]\n",
    "    print(key)\n",
    "    dict[key] = i\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "list[dict['FMN']] =list[0]  \n",
    "print(list)\n",
    "heapq.heappop(list)\n",
    "print(list)\n",
    "heapq.heappush(list, (-10,'MOMOKA >w<' , 'hiniatura'))\n",
    "print(list)\n",
    "\n",
    "\n",
    "    "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T08:04:09.237444Z",
     "start_time": "2024-06-18T08:04:09.230542Z"
    }
   },
   "source": [
    "%pwd\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretraining init distance matrix and heap for distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T08:09:43.401051Z",
     "start_time": "2024-06-18T08:06:57.034774Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from Cluster_Models.Agglomerate_method import AgglomerativeMethod \n",
    "from scipy.spatial import distance_matrix  ,KDTree \n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "np_mean = pd.read_csv('train_mean.csv')\n",
    "\n",
    "#data = np.array([[1, 2], [2, 3], [3, 4], [8, 9], [9, 10], [10, 11]])\n",
    "\n",
    "\n",
    "\n",
    "np_mean = np_mean.to_numpy()\n",
    "cluster_method = AgglomerativeMethod(data=np_mean  , cluster_number=20)\n",
    "cluster_method.init_clusters()\n",
    "cluster_method.init_distance_matrix_heap()\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "cluster_method.fit_a()"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
